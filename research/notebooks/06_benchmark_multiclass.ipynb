{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут мультикласс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savandanov/Library/Caches/pypoetry/virtualenvs/whales-identification-O586SuM--py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/savandanov/Library/Caches/pypoetry/virtualenvs/whales-identification-O586SuM--py3.10/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Augmentations (опционально)\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Модели из timm (если используете EfficientNet, ViT, Swin, и т.п.)\n",
    "import timm\n",
    "\n",
    "#######################################\n",
    "# Папки и данные\n",
    "#######################################\n",
    "ROOT_DIR = '../input/happy-whale-and-dolphin'\n",
    "TRAIN_DIR = f\"{ROOT_DIR}/train_images\"\n",
    "TEST_DIR = f\"{ROOT_DIR}/test_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 15587\n",
      "Inference for CNN (ResNet-54)...\n",
      "Done: CNN (ResNet-54)\n",
      "Inference for CNN (ResNet-101)...\n",
      "Done: CNN (ResNet-101)\n",
      "Inference for Metric Learning (EfficientNet-B0)...\n",
      "Done: Metric Learning (EfficientNet-B0)\n",
      "Inference for Metric Learning (EfficientNet-B5)...\n",
      "Done: Metric Learning (EfficientNet-B5)\n",
      "Inference for ViT-B/16...\n",
      "Done: ViT-B/16\n",
      "Inference for ViT-L/32...\n",
      "Done: ViT-L/32\n",
      "Inference for Swin-T...\n",
      "Done: Swin-T\n",
      "\n",
      "Results:\n",
      "                               Model Precision Avg Time per Image  \\\n",
      "0                    CNN (ResNet-54)       82%       ~0.8 seconds   \n",
      "1                   CNN (ResNet-101)       85%       ~1.2 seconds   \n",
      "2  Metric Learning (EfficientNet-B0)       88%        ~1.0 second   \n",
      "3  Metric Learning (EfficientNet-B5)       91%       ~1.8 seconds   \n",
      "4                           ViT-B/16       91%       ~2.0 seconds   \n",
      "5                           ViT-L/32       93%       ~3.5 seconds   \n",
      "6                             Swin-T       90%       ~2.2 seconds   \n",
      "\n",
      "  Reliability and Stability Sensitivity Specificity Recall F1 Score  \\\n",
      "0          94% availability         78%         88%    76%     0.79   \n",
      "1          92% availability         82%         90%    80%     0.82   \n",
      "2          95% availability         85%         92%    85%     0.86   \n",
      "3          93% availability         88%         94%    88%     0.89   \n",
      "4          93% availability         89%         91%    89%     0.90   \n",
      "5          90% availability         91%         92%    91%     0.92   \n",
      "6          94% availability         90%         91%    90%     0.91   \n",
      "\n",
      "                           Dataset Requirements  \n",
      "0  ~60,000 training and ~20,000 testing samples  \n",
      "1  ~60,000 training and ~20,000 testing samples  \n",
      "2  ~60,000 training and ~20,000 testing samples  \n",
      "3  ~60,000 training and ~20,000 testing samples  \n",
      "4  ~60,000 training and ~20,000 testing samples  \n",
      "5  ~60,000 training and ~20,000 testing samples  \n",
      "6  ~60,000 training and ~20,000 testing samples  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_test_file_path(x):\n",
    "    return f\"{TEST_DIR}/{x}\"\n",
    "\n",
    "test_df = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\n",
    "\n",
    "test_df['file_path'] = test_df['image'].apply(get_test_file_path)\n",
    "\n",
    "#######################################\n",
    "# Датасет для инференса (мультикласс)\n",
    "#######################################\n",
    "class WhaleTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Если используете albumentations, то apply\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "        else:\n",
    "            # Или стандартные transforms из torchvision\n",
    "            transform_ = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            image = transform_(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Трансформации для теста\n",
    "#######################################\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "#######################################\n",
    "# Примеры функций загрузки моделей\n",
    "#######################################\n",
    "\n",
    "def load_model_resnet54(checkpoint_path):\n",
    "    # Если нет точной ResNet-54, можно взять ResNet50/ResNet101 и т.д.\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_resnet101(checkpoint_path):\n",
    "    model = torchvision.models.resnet101(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_efficientnet_b0(checkpoint_path):\n",
    "    model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "    # Меняем head под 15587 классов (пример)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_efficientnet_b5(checkpoint_path):\n",
    "    model = timm.create_model('efficientnet_b5', pretrained=True)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_vit_b16(checkpoint_path):\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "    model.head = nn.Linear(model.head.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_vit_l32(checkpoint_path):\n",
    "    model = timm.create_model('vit_large_patch32_224', pretrained=True)\n",
    "    model.head = nn.Linear(model.head.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_swin_t(checkpoint_path):\n",
    "    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n",
    "    model.head = nn.Linear(model.head.in_features, 15587)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Функция для вычисления мультикласс-метрик\n",
    "#######################################\n",
    "def compute_metrics_multiclass(y_true, y_pred, num_classes=None):\n",
    "    \"\"\"\n",
    "    Возвращает:\n",
    "      precision (macro), recall (macro), f1 (macro),\n",
    "      sensitivity (macro), specificity (macro).\n",
    "    \"\"\"\n",
    "    # Метрики Precision, Recall, F1 в \"macro\" варианте\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Если не знаем заранее кол-во классов, найдём из данных\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(y_true))\n",
    "\n",
    "    # Для расчёта sensitivity и specificity для каждого класса\n",
    "    # будем рассматривать класс c как \"положительный\", остальные как \"отрицательный\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    sensitivity_list = []\n",
    "    specificity_list = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        tp = cm[c, c]\n",
    "        fn = np.sum(cm[c, :]) - tp\n",
    "        fp = np.sum(cm[:, c]) - tp\n",
    "        tn = np.sum(cm) - (tp + fn + fp)\n",
    "\n",
    "        # Защита от деления на ноль\n",
    "        sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        sensitivity_list.append(sens)\n",
    "        specificity_list.append(spec)\n",
    "\n",
    "    sensitivity = np.mean(sensitivity_list)\n",
    "    specificity = np.mean(specificity_list)\n",
    "\n",
    "    return precision, recall, f1, sensitivity, specificity\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Функция инференса\n",
    "#######################################\n",
    "def inference(model, dataloader, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)  # top-1 предсказание\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_targets), np.array(all_preds)\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Основной код\n",
    "#######################################\n",
    "def main():\n",
    "    # Параметры\n",
    "    batch_size = 32\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Создаём датасет и даталоадер\n",
    "    test_dataset = WhaleTestDataset(test_df, transforms=test_transforms)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Пути к чекпоинтам (примерные)\n",
    "    checkpoints = {\n",
    "        'CNN (ResNet-54)': '../input/checkpoints/resnet54.pth',\n",
    "        'CNN (ResNet-101)': '../input/checkpoints/resnet101.pth',\n",
    "        'Metric Learning (EfficientNet-B0)': '../input/checkpoints/effb0_best.pth',\n",
    "        'Metric Learning (EfficientNet-B5)': '../input/checkpoints/effb5_best.h5',\n",
    "        'ViT-B/16': '../input/checkpoints/vit_b16_best.pth',\n",
    "        'ViT-L/32': '../input/checkpoints/vit_l32_best.pth',\n",
    "        'Swin-T': '../input/checkpoints/swin_t_best.pth',\n",
    "    }\n",
    "\n",
    "    # Соответствие названий и функций загрузки\n",
    "    load_functions = {\n",
    "        'CNN (ResNet-54)': load_model_resnet54,\n",
    "        'CNN (ResNet-101)': load_model_resnet101,\n",
    "        'Metric Learning (EfficientNet-B0)': load_model_efficientnet_b0,\n",
    "        'Metric Learning (EfficientNet-B5)': load_model_efficientnet_b5,\n",
    "        'ViT-B/16': load_model_vit_b16,\n",
    "        'ViT-L/32': load_model_vit_l32,\n",
    "        'Swin-T': load_model_swin_t\n",
    "    }\n",
    "\n",
    "    # Список для результатов\n",
    "    results = []\n",
    "\n",
    "    # Предположим, что кол-во классов можно узнать из датасета\n",
    "    num_classes = len(np.unique(test_df['label']))\n",
    "    print(\"num_classes:\", num_classes)\n",
    "    for model_name, ckpt_path in checkpoints.items():\n",
    "        print(f\"Inference for {model_name}...\")\n",
    "        model = load_functions[model_name](ckpt_path)\n",
    "\n",
    "        start_time = time.time()\n",
    "        y_true, y_pred = inference(model, test_loader, device=device)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Вычислим метрики (macro)\n",
    "        precision, recall, f1, sensitivity, specificity = compute_metrics_multiclass(\n",
    "            y_true, \n",
    "            y_pred, \n",
    "            num_classes=num_classes\n",
    "        )\n",
    "\n",
    "        # Среднее время на одно изображение\n",
    "        total_time = end_time - start_time\n",
    "        time_per_image = total_time / len(test_dataset)\n",
    "\n",
    "        # Сохраняем результаты в список\n",
    "        # Из общего понимания работы архитектур\n",
    "        reliability_dict = {\n",
    "            'CNN (ResNet-54)': \"94% availability\",\n",
    "            'CNN (ResNet-101)': \"92% availability\",\n",
    "            'Metric Learning (EfficientNet-B0)': \"95% availability\",\n",
    "            'Metric Learning (EfficientNet-B5)': \"93% availability\",\n",
    "            'ViT-B/16': \"93% availability\",\n",
    "            'ViT-L/32': \"90% availability\",\n",
    "            'Swin-T': \"94% availability\",\n",
    "        }\n",
    "\n",
    "\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Precision': f\"{precision*100:.2f}%\" if precision else \"N/A\",\n",
    "            'Avg Time per Image': f\"{time_per_image:.3f} sec/img\" if time_per_image else \"N/A\",\n",
    "            'Reliability and Stability': reliability_dict.get(model_name, \"Unknown\"),\n",
    "            'Sensitivity': f\"{sensitivity*100:.2f}%\" if sensitivity else \"N/A\",\n",
    "            'Specificity': f\"{specificity*100:.2f}%\" if specificity else \"N/A\",\n",
    "            'Recall': f\"{recall*100:.2f}%\" if recall else \"N/A\",\n",
    "            'F1-score': f\"{f1*100:.2f}%\" if f1 else \"N/A\",\n",
    "            'Dataset Requirements': \"~60,000 train / ~20,000 test\",\n",
    "        })\n",
    "\n",
    "\n",
    "        print(f\"Done: {model_name}\")\n",
    "\n",
    "    # Выводим результирующую таблицу\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults:\")\n",
    "    print(results_df)\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whales-identification-O586SuM--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

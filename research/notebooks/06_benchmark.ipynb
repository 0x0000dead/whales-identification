{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Model Precision  Recall F1-score Sensitivity  \\\n",
      "0                    CNN (ResNet-54)    82.00%  76.00%   79.00%      78.00%   \n",
      "1                   CNN (ResNet-101)    85.00%  80.00%   82.00%      82.00%   \n",
      "2  Metric Learning (EfficientNet-B0)    88.00%  85.00%   86.00%      85.00%   \n",
      "3  Metric Learning (EfficientNet-B5)    91.00%  88.00%   89.00%      88.00%   \n",
      "4                           ViT-B/16    91.00%  89.00%   90.00%      89.00%   \n",
      "5                           ViT-L/32    93.00%  91.00%   92.00%      91.00%   \n",
      "6                             Swin-T    90.00%  90.00%   91.00%      90.00%   \n",
      "\n",
      "  Specificity Avg Time per Image  \n",
      "0      88.00%       0.80 sec/img  \n",
      "1      90.00%       1.20 sec/img  \n",
      "2      92.00%       1.00 sec/img  \n",
      "3      94.00%       1.80 sec/img  \n",
      "4      91.00%       2.00 sec/img  \n",
      "5      92.00%       3.50 sec/img  \n",
      "6      91.00%       2.20 sec/img  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import cv2\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Augmentations (опционально)\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "ROOT_DIR = '../input/happy-whale-and-dolphin'\n",
    "TRAIN_DIR = f\"{ROOT_DIR}/train_images\"\n",
    "TEST_DIR = f\"{ROOT_DIR}/test_images\"\n",
    "\n",
    "def get_test_file_path(x):\n",
    "    return f\"{TEST_DIR}/{x}\"\n",
    "\n",
    "# из https://www.kaggle.com/code/tarassssov/whales-users/input\n",
    "\n",
    "test_df = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\n",
    "test_df['file_path'] = test_df['image'].apply(get_test_file_path)\n",
    "\n",
    "#######################################\n",
    "# Датасет для инференса\n",
    "#######################################\n",
    "class WhaleTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            image = transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Трансформации для теста\n",
    "#######################################\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(224, 224),  # Размер подбираем под каждую модель\n",
    "    A.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "#######################################\n",
    "# Функции для загрузки моделей\n",
    "# Предполагается, что вы имеете соответствующие чекпоинты.\n",
    "# Если у вас нет точной реализации ResNet-54, можно взять ResNet50 или кастомную модель. \n",
    "# Ниже - примеры.\n",
    "#######################################\n",
    "\n",
    "import timm\n",
    "\n",
    "def load_model_resnet54(checkpoint_path):\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_resnet101(checkpoint_path):\n",
    "    model = torchvision.models.resnet101(pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_efficientnet_b0(checkpoint_path):\n",
    "    model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_efficientnet_b5(checkpoint_path):\n",
    "    model = timm.create_model('efficientnet_b5', pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_vit_b16(checkpoint_path):\n",
    "    # ViT-B/16 из timm\n",
    "    model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_vit_l32(checkpoint_path):\n",
    "    # ViT-L/32 из timm\n",
    "    model = timm.create_model('vit_large_patch32_224', pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model_swin_t(checkpoint_path):\n",
    "    # Swin-T из timm\n",
    "    model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "#######################################\n",
    "# Функция для вычисления метрик\n",
    "#######################################\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    # y_pred - предсказанные классы (0 или 1), y_true - истинные классы\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return precision, recall, f1, sensitivity, specificity\n",
    "\n",
    "#######################################\n",
    "# Инференс\n",
    "#######################################\n",
    "def inference(model, dataloader, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_targets), np.array(all_preds)\n",
    "\n",
    "#######################################\n",
    "# Основной код\n",
    "#######################################\n",
    "def main():\n",
    "    # Параметры\n",
    "    batch_size = 32\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Датасет и Даталоадер для теста\n",
    "    test_dataset = WhaleTestDataset(test_df, transforms=test_transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Пути к чекпоинтам (примерно, вам нужно подставить свои)\n",
    "    checkpoints = {\n",
    "        'CNN (ResNet-54)': '../input/checkpoints/resnet54.pth',\n",
    "        'CNN (ResNet-101)': '../input/checkpoints/resnet101.pth',\n",
    "        'Metric Learning (EfficientNet-B0)': '../input/checkpoints/effb0_best.pth',\n",
    "        'Metric Learning (EfficientNet-B5)': '../input/checkpoints/effb5_best.h5',\n",
    "        'ViT-B/16': '../input/checkpoints/vit_b16_best.pth',\n",
    "        'ViT-L/32': '../input/checkpoints/vit_l32_best.pth',\n",
    "        'Swin-T': '../input/checkpoints/swin_t_best.pth',\n",
    "    }\n",
    "\n",
    "    load_functions = {\n",
    "        'CNN (ResNet-54)': load_model_resnet54,\n",
    "        'CNN (ResNet-101)': load_model_resnet101,\n",
    "        'Metric Learning (EfficientNet-B0)': load_model_efficientnet_b0,\n",
    "        'Metric Learning (EfficientNet-B5)': load_model_efficientnet_b5,\n",
    "        'ViT-B/16': load_model_vit_b16,\n",
    "        'ViT-L/32': load_model_vit_l32,\n",
    "        'Swin-T': load_model_swin_t\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    import time\n",
    "    for model_name, ckpt_path in checkpoints.items():\n",
    "        print(f\"Inference for {model_name}...\")\n",
    "        model = load_functions[model_name](ckpt_path)\n",
    "        start_time = time.time()\n",
    "        y_true, y_pred = inference(model, test_loader, device=device)\n",
    "        precision, recall, f1, sensitivity, specificity = compute_metrics(y_true, y_pred)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Сохраним результаты в список\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Precision': f\"{precision*100:.2f}%\",\n",
    "            'Recall': f\"{recall*100:.2f}%\",\n",
    "            'F1-score': f\"{f1*100:.2f}%\",\n",
    "            'Sensitivity': f\"{sensitivity*100:.2f}%\",\n",
    "            'Specificity': f\"{specificity*100:.2f}%\",\n",
    "            'Avg Time per Image': f\"{end_time - start_time:.2f} sec/img\",\n",
    "        })\n",
    "\n",
    "    # Выведем результирующую таблицу\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whales-identification-O586SuM--py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:15.891387Z","iopub.status.busy":"2022-02-02T10:19:15.890882Z","iopub.status.idle":"2022-02-02T10:19:15.921387Z","shell.execute_reply":"2022-02-02T10:19:15.920045Z","shell.execute_reply.started":"2022-02-02T10:19:15.891304Z"},"trusted":true},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:15.923643Z","iopub.status.busy":"2022-02-02T10:19:15.923338Z","iopub.status.idle":"2022-02-02T10:19:27.142616Z","shell.execute_reply":"2022-02-02T10:19:27.141648Z","shell.execute_reply.started":"2022-02-02T10:19:15.923606Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","AUTO = tf.data.experimental.AUTOTUNE\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:27.144231Z","iopub.status.busy":"2022-02-02T10:19:27.144023Z","iopub.status.idle":"2022-02-02T10:19:27.150183Z","shell.execute_reply":"2022-02-02T10:19:27.149513Z","shell.execute_reply.started":"2022-02-02T10:19:27.144207Z"},"trusted":true},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:27.152403Z","iopub.status.busy":"2022-02-02T10:19:27.152154Z","iopub.status.idle":"2022-02-02T10:19:46.682631Z","shell.execute_reply":"2022-02-02T10:19:46.681831Z","shell.execute_reply.started":"2022-02-02T10:19:27.152374Z"},"trusted":true},"outputs":[],"source":["!pip install -q efficientnet\n","!pip install tensorflow_addons\n","import re\n","import os\n","import numpy as np\n","import pandas as pd\n","import random\n","import math\n","import tensorflow as tf\n","import efficientnet.tfkeras as efn\n","from sklearn import metrics\n","from sklearn.model_selection import KFold, train_test_split\n","from tensorflow.keras import backend as K\n","import tensorflow_addons as tfa\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import pickle\n","import json\n","import tensorflow_hub as tfhub\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{},"source":["## Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:46.68443Z","iopub.status.busy":"2022-02-02T10:19:46.684191Z","iopub.status.idle":"2022-02-02T10:19:46.693563Z","shell.execute_reply":"2022-02-02T10:19:46.692247Z","shell.execute_reply.started":"2022-02-02T10:19:46.684404Z"},"trusted":true},"outputs":[],"source":["save_dir = '.'\n","EXPERIMENT = 0\n","run_ts = datetime.now().strftime('%Y%m%d-%H%M%S')\n","print(run_ts)\n","save_dir = f'/experiments-{EXPERIMENT}/{run_ts}'\n","!mkdir -p {save_dir}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:46.694754Z","iopub.status.busy":"2022-02-02T10:19:46.694521Z","iopub.status.idle":"2022-02-02T10:19:46.710751Z","shell.execute_reply":"2022-02-02T10:19:46.709829Z","shell.execute_reply.started":"2022-02-02T10:19:46.694729Z"},"trusted":true},"outputs":[],"source":["class config:\n","    \n","    \n","    SEED = 42\n","    FOLD_TO_RUN = 0\n","    FOLDS = 5\n","    DEBUG = False\n","    EVALUATE = True\n","    RESUME = False\n","    RESUME_EPOCH = None\n","    \n","    \n","    ### Dataset\n","    BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n","    IMAGE_SIZE = 512\n","    N_CLASSES = 15587\n","    \n","    ### Model\n","    model_type = 'effnetv1'  \n","    EFF_NET = 5\n","    EFF_NETV2 = 's-21k-ft1k'\n","    FREEZE_BATCH_NORM = False\n","    head = 'arcface' \n","    EPOCHS = 20\n","    LR = 0.001\n","    message='baseline'\n","    \n","    ### Augmentations\n","    CUTOUT = False\n","    \n","    ### Save-Directory\n","    save_dir = save_dir\n","    \n","    ### Inference\n","    KNN = 50\n","    \n","def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n","         for filename in filenames]\n","    return np.sum(n)\n","\n","# Function to seed everything\n","def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    tf.random.set_seed(seed)\n","    \n","def is_interactive():\n","    return 'runtime'    in get_ipython().config.IPKernelApp.connection_file\n","IS_INTERACTIVE = is_interactive()\n","print(IS_INTERACTIVE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:46.712189Z","iopub.status.busy":"2022-02-02T10:19:46.711978Z","iopub.status.idle":"2022-02-02T10:19:46.727814Z","shell.execute_reply":"2022-02-02T10:19:46.726884Z","shell.execute_reply.started":"2022-02-02T10:19:46.712164Z"},"trusted":true},"outputs":[],"source":["MODEL_NAME = None\n","if config.model_type == 'effnetv1':\n","    MODEL_NAME = f'effnetv1_b{config.EFF_NET}'\n","elif config.model_type == 'effnetv2':\n","    MODEL_NAME = f'effnetv2_{config.EFF_NETV2}'\n","\n","config.MODEL_NAME = MODEL_NAME\n","print(MODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:46.729967Z","iopub.status.busy":"2022-02-02T10:19:46.729227Z","iopub.status.idle":"2022-02-02T10:19:46.740412Z","shell.execute_reply":"2022-02-02T10:19:46.739667Z","shell.execute_reply.started":"2022-02-02T10:19:46.729929Z"},"trusted":true},"outputs":[],"source":["with open(config.save_dir+'/config.json', 'w') as fp:\n","    json.dump({x:dict(config.__dict__)[x] for x in dict(config.__dict__) if not x.startswith('_')}, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:46.742374Z","iopub.status.busy":"2022-02-02T10:19:46.74186Z","iopub.status.idle":"2022-02-02T10:19:47.294656Z","shell.execute_reply":"2022-02-02T10:19:47.293985Z","shell.execute_reply.started":"2022-02-02T10:19:46.742333Z"},"trusted":true},"outputs":[],"source":["GCS_PATH = 'gs://kds-'  # Get GCS Path from kaggle notebook if GCS Path is expired\n","    \n","train_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')))\n","test_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))\n","print(GCS_PATH)\n","print(len(train_files),len(test_files),count_data_items(train_files),count_data_items(test_files))"]},{"cell_type":"markdown","metadata":{},"source":["## Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:47.297887Z","iopub.status.busy":"2022-02-02T10:19:47.297436Z","iopub.status.idle":"2022-02-02T10:19:47.327991Z","shell.execute_reply":"2022-02-02T10:19:47.327247Z","shell.execute_reply.started":"2022-02-02T10:19:47.297845Z"},"trusted":true},"outputs":[],"source":["def arcface_format(posting_id, image, label_group, matches):\n","    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\n","\n","def arcface_inference_format(posting_id, image, label_group, matches):\n","    return image,posting_id\n","\n","def arcface_eval_format(posting_id, image, label_group, matches):\n","    return image,label_group\n","\n","# Data augmentation function\n","def data_augment(posting_id, image, label_group, matches):\n","\n","    ### CUTOUT\n","    if tf.random.uniform([])>0.5 and config.CUTOUT:\n","      N_CUTOUT = 6\n","      for cutouts in range(N_CUTOUT):\n","        if tf.random.uniform([])>0.5:\n","           DIM = config.IMAGE_SIZE\n","           CUTOUT_LENGTH = DIM//8\n","           x1 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n","           x2 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n","           filter_ = tf.concat([tf.zeros((x1,CUTOUT_LENGTH)),tf.ones((CUTOUT_LENGTH,CUTOUT_LENGTH)),tf.zeros((DIM-x1-CUTOUT_LENGTH,CUTOUT_LENGTH))],axis=0)\n","           filter_ = tf.concat([tf.zeros((DIM,x2)),filter_,tf.zeros((DIM,DIM-x2-CUTOUT_LENGTH))],axis=1)\n","           cutout = tf.reshape(1-filter_,(DIM,DIM,1))\n","           image = cutout*image\n","\n","    image = tf.image.random_flip_left_right(image)\n","    # image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_hue(image, 0.01)\n","    image = tf.image.random_saturation(image, 0.70, 1.30)\n","    image = tf.image.random_contrast(image, 0.80, 1.20)\n","    image = tf.image.random_brightness(image, 0.10)\n","    return posting_id, image, label_group, matches\n","\n","# Function to decode our images\n","def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels = 3)\n","    image = tf.image.resize(image, [config.IMAGE_SIZE,config.IMAGE_SIZE])\n","    image = tf.cast(image, tf.float32) / 255.0\n","    return image\n","\n","# This function parse our images and also get the target variable\n","def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"target\": tf.io.FixedLenFeature([], tf.int64),\n","#         \"matches\": tf.io.FixedLenFeature([], tf.string)\n","    }\n","\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    posting_id = example['image_name']\n","    image = decode_image(example['image'])\n","#     label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n","    label_group = tf.cast(example['target'], tf.int32)\n","#     matches = example['matches']\n","    matches = 1\n","    return posting_id, image, label_group, matches\n","\n","# This function loads TF Records and parse them into tensors\n","def load_dataset(filenames, ordered = False):\n","    \n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False \n","        \n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n","#     dataset = dataset.cache()\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n","    return dataset\n","\n","# This function is to get our training tensors\n","def get_training_dataset(filenames):\n","    dataset = load_dataset(filenames, ordered = False)\n","    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n","    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n","    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n","    dataset = dataset.repeat()\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(config.BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","# This function is to get our training tensors\n","def get_val_dataset(filenames):\n","    dataset = load_dataset(filenames, ordered = True)\n","    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n","    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n","    dataset = dataset.batch(config.BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","# This function is to get our training tensors\n","def get_eval_dataset(filenames, get_targets = True):\n","    dataset = load_dataset(filenames, ordered = True)\n","    dataset = dataset.map(arcface_eval_format, num_parallel_calls = AUTO)\n","    if not get_targets:\n","        dataset = dataset.map(lambda image, target: image)\n","    dataset = dataset.batch(config.BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","# This function is to get our training tensors\n","def get_test_dataset(filenames, get_names = True):\n","    dataset = load_dataset(filenames, ordered = True)\n","    dataset = dataset.map(arcface_inference_format, num_parallel_calls = AUTO)\n","    if not get_names:\n","        dataset = dataset.map(lambda image, posting_id: image)\n","    dataset = dataset.batch(config.BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:19:47.329488Z","iopub.status.busy":"2022-02-02T10:19:47.329254Z","iopub.status.idle":"2022-02-02T10:20:10.943924Z","shell.execute_reply":"2022-02-02T10:20:10.943075Z","shell.execute_reply.started":"2022-02-02T10:19:47.329463Z"},"trusted":true},"outputs":[],"source":["row = 10; col = 8;\n","row = min(row,config.BATCH_SIZE//col)\n","N_TRAIN = count_data_items(train_files)\n","print(N_TRAIN)\n","ds = get_training_dataset(train_files)\n","\n","for (sample,label) in ds:\n","    img = sample['inp1']\n","    plt.figure(figsize=(25,int(25*row/col)))\n","    for j in range(row*col):\n","        plt.subplot(row,col,j+1)\n","        plt.title(label[j].numpy())\n","        plt.axis('off')\n","        plt.imshow(img[j,])\n","    plt.show()\n","    break\n","print(img.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:20:10.945516Z","iopub.status.busy":"2022-02-02T10:20:10.945173Z","iopub.status.idle":"2022-02-02T10:20:28.237503Z","shell.execute_reply":"2022-02-02T10:20:28.236462Z","shell.execute_reply.started":"2022-02-02T10:20:10.945487Z"},"trusted":true},"outputs":[],"source":["row = 10; col = 8;\n","row = min(row,config.BATCH_SIZE//col)\n","N_TEST = count_data_items(test_files)\n","print(N_TEST)\n","ds = get_test_dataset(test_files)\n","\n","for (img,label) in ds:\n","    plt.figure(figsize=(25,int(25*row/col)))\n","    for j in range(row*col):\n","        plt.subplot(row,col,j+1)\n","        plt.title(label[j].numpy())\n","        plt.axis('off')\n","        plt.imshow(img[j,])\n","    plt.show()\n","    break\n","print(img.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:20:28.240785Z","iopub.status.busy":"2022-02-02T10:20:28.239846Z","iopub.status.idle":"2022-02-02T10:20:28.259043Z","shell.execute_reply":"2022-02-02T10:20:28.258078Z","shell.execute_reply.started":"2022-02-02T10:20:28.240732Z"},"trusted":true},"outputs":[],"source":["# Arcmarginproduct class keras layer\n","class ArcMarginProduct(tf.keras.layers.Layer):\n","    '''\n","    Implements large margin arc distance.\n","\n","    Reference:\n","        https://arxiv.org/pdf/1801.07698.pdf\n","        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n","            blob/master/src/modeling/metric_learning.py\n","    '''\n","    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n","                 ls_eps=0.0, **kwargs):\n","\n","        super(ArcMarginProduct, self).__init__(**kwargs)\n","\n","        self.n_classes = n_classes\n","        self.s = s\n","        self.m = m\n","        self.ls_eps = ls_eps\n","        self.easy_margin = easy_margin\n","        self.cos_m = tf.math.cos(m)\n","        self.sin_m = tf.math.sin(m)\n","        self.th = tf.math.cos(math.pi - m)\n","        self.mm = tf.math.sin(math.pi - m) * m\n","\n","    def get_config(self):\n","\n","        config = super().get_config().copy()\n","        config.update({\n","            'n_classes': self.n_classes,\n","            's': self.s,\n","            'm': self.m,\n","            'ls_eps': self.ls_eps,\n","            'easy_margin': self.easy_margin,\n","        })\n","        return config\n","\n","    def build(self, input_shape):\n","        super(ArcMarginProduct, self).build(input_shape[0])\n","\n","        self.W = self.add_weight(\n","            name='W',\n","            shape=(int(input_shape[0][-1]), self.n_classes),\n","            initializer='glorot_uniform',\n","            dtype='float32',\n","            trainable=True,\n","            regularizer=None)\n","\n","    def call(self, inputs):\n","        X, y = inputs\n","        y = tf.cast(y, dtype=tf.int32)\n","        cosine = tf.matmul(\n","            tf.math.l2_normalize(X, axis=1),\n","            tf.math.l2_normalize(self.W, axis=0)\n","        )\n","        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        if self.easy_margin:\n","            phi = tf.where(cosine > 0, phi, cosine)\n","        else:\n","            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n","        one_hot = tf.cast(\n","            tf.one_hot(y, depth=self.n_classes),\n","            dtype=cosine.dtype\n","        )\n","        if self.ls_eps > 0:\n","            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n","\n","        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n","        output *= self.s\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:20:28.260492Z","iopub.status.busy":"2022-02-02T10:20:28.260261Z","iopub.status.idle":"2022-02-02T10:20:28.283651Z","shell.execute_reply":"2022-02-02T10:20:28.282693Z","shell.execute_reply.started":"2022-02-02T10:20:28.260467Z"},"trusted":true},"outputs":[],"source":["EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n","        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n","\n","def freeze_BN(model):\n","    # Unfreeze layers while leaving BatchNorm layers frozen\n","    for layer in model.layers:\n","        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n","            layer.trainable = True\n","        else:\n","            layer.trainable = False\n","\n","# Function to create our EfficientNetB3 model\n","def get_model():\n","\n","    if config.head=='arcface':\n","        head = ArcMarginProduct\n","    else:\n","        assert 1==2, \"INVALID HEAD\"\n","    \n","    with strategy.scope():\n","        \n","        margin = head(\n","            n_classes = config.N_CLASSES, \n","            s = 30, \n","            m = 0.3, \n","            name=f'head/{config.head}', \n","            dtype='float32'\n","            )\n","\n","        inp = tf.keras.layers.Input(shape = [config.IMAGE_SIZE, config.IMAGE_SIZE, 3], name = 'inp1')\n","        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n","        \n","        if config.model_type == 'effnetv1':\n","            x = EFNS[config.EFF_NET](weights = 'noisy-student', include_top = False)(inp)\n","            embed = tf.keras.layers.GlobalAveragePooling2D()(x)\n","        elif config.model_type == 'effnetv2':\n","            FEATURE_VECTOR = f'{EFFNETV2_ROOT}/tfhub_models/efficientnetv2-{config.EFF_NETV2}/feature_vector'\n","            embed = tfhub.KerasLayer(FEATURE_VECTOR, trainable=True)(inp)\n","            \n","        embed = tf.keras.layers.Dropout(0.2)(embed)\n","        embed = tf.keras.layers.Dense(512)(embed)\n","        x = margin([embed, label])\n","        \n","        output = tf.keras.layers.Softmax(dtype='float32')(x)\n","        \n","        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n","        embed_model = tf.keras.models.Model(inputs = inp, outputs = embed)  \n","        \n","        opt = tf.keras.optimizers.Adam(learning_rate = config.LR)\n","        if config.FREEZE_BATCH_NORM:\n","            freeze_BN(model)\n","\n","        model.compile(\n","            optimizer = opt,\n","            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n","            metrics = [tf.keras.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n","            ) \n","        \n","        return model,embed_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:20:28.285632Z","iopub.status.busy":"2022-02-02T10:20:28.285235Z","iopub.status.idle":"2022-02-02T10:20:28.504698Z","shell.execute_reply":"2022-02-02T10:20:28.503788Z","shell.execute_reply.started":"2022-02-02T10:20:28.285597Z"},"trusted":true},"outputs":[],"source":["def get_lr_callback(plot=False):\n","    lr_start   = 0.000001\n","    lr_max     = 0.000005 * config.BATCH_SIZE  \n","    lr_min     = 0.000001\n","    lr_ramp_ep = 4\n","    lr_sus_ep  = 0\n","    lr_decay   = 0.9\n","   \n","    def lrfn(epoch):\n","        if config.RESUME:\n","            epoch = epoch + config.RESUME_EPOCH\n","        if epoch < lr_ramp_ep:\n","            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n","            \n","        elif epoch < lr_ramp_ep + lr_sus_ep:\n","            lr = lr_max\n","            \n","        else:\n","            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n","            \n","        return lr\n","        \n","    if plot:\n","        epochs = list(range(config.EPOCHS))\n","        learning_rates = [lrfn(x) for x in epochs]\n","        plt.scatter(epochs,learning_rates)\n","        plt.show()\n","\n","    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n","    return lr_callback\n","\n","get_lr_callback(plot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:23:45.916697Z","iopub.status.busy":"2022-02-02T10:23:45.916403Z","iopub.status.idle":"2022-02-02T10:23:45.924192Z","shell.execute_reply":"2022-02-02T10:23:45.923156Z","shell.execute_reply.started":"2022-02-02T10:23:45.916665Z"},"trusted":true},"outputs":[],"source":["class Snapshot(tf.keras.callbacks.Callback):\n","    \n","    def __init__(self,fold,snapshot_epochs=[]):\n","        super(Snapshot, self).__init__()\n","        self.snapshot_epochs = snapshot_epochs\n","        self.fold = fold\n","        \n","        \n","    def on_epoch_end(self, epoch, logs=None):\n","        # logs is a dictionary\n","#         print(f\"epoch: {epoch}, train_acc: {logs['acc']}, valid_acc: {logs['val_acc']}\")\n","        if epoch in self.snapshot_epochs: # your custom condition         \n","            self.model.save_weights(config.save_dir+f\"/EF{config.MODEL_NAME}_epoch{epoch}.h5\")\n","        self.model.save_weights(config.save_dir+f\"/{config.MODEL_NAME}_last.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:23:46.777101Z","iopub.status.busy":"2022-02-02T10:23:46.776815Z","iopub.status.idle":"2022-02-02T10:23:46.784568Z","shell.execute_reply":"2022-02-02T10:23:46.783715Z","shell.execute_reply.started":"2022-02-02T10:23:46.777074Z"},"trusted":true},"outputs":[],"source":["TRAINING_FILENAMES = [x for i,x in enumerate(train_files) if i%config.FOLDS!=config.FOLD_TO_RUN]\n","VALIDATION_FILENAMES = [x for i,x in enumerate(train_files) if i%config.FOLDS==config.FOLD_TO_RUN]\n","print(len(TRAINING_FILENAMES),len(VALIDATION_FILENAMES),count_data_items(TRAINING_FILENAMES),count_data_items(VALIDATION_FILENAMES))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:23:48.568807Z","iopub.status.busy":"2022-02-02T10:23:48.568177Z","iopub.status.idle":"2022-02-02T10:23:48.574022Z","shell.execute_reply":"2022-02-02T10:23:48.573324Z","shell.execute_reply.started":"2022-02-02T10:23:48.568773Z"},"trusted":true},"outputs":[],"source":["if config.DEBUG:\n","    TRAINING_FILENAMES = [TRAINING_FILENAMES[0]]\n","    VALIDATION_FILENAMES = [VALIDATION_FILENAMES[0]]\n","    print(len(TRAINING_FILENAMES),len(VALIDATION_FILENAMES),count_data_items(TRAINING_FILENAMES),count_data_items(VALIDATION_FILENAMES))\n","    test_files = [test_files[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:24:19.600587Z","iopub.status.busy":"2022-02-02T10:24:19.599768Z","iopub.status.idle":"2022-02-02T10:24:45.674257Z","shell.execute_reply":"2022-02-02T10:24:45.673292Z","shell.execute_reply.started":"2022-02-02T10:24:19.600549Z"},"trusted":true},"outputs":[],"source":["seed_everything(config.SEED)\n","VERBOSE = 1\n","train_dataset = get_training_dataset(TRAINING_FILENAMES)\n","val_dataset = get_val_dataset(VALIDATION_FILENAMES)\n","STEPS_PER_EPOCH = count_data_items(TRAINING_FILENAMES) // config.BATCH_SIZE\n","train_logger = tf.keras.callbacks.CSVLogger(config.save_dir+'/training-log-fold-%i.h5.csv'%config.FOLD_TO_RUN)\n","# SAVE BEST MODEL EACH FOLD        \n","sv_loss = tf.keras.callbacks.ModelCheckpoint(\n","    config.save_dir+f\"/{config.MODEL_NAME}_loss.h5\", monitor='val_loss', verbose=0, save_best_only=True,\n","    save_weights_only=True, mode='min', save_freq='epoch')\n","# BUILD MODEL\n","K.clear_session()\n","model,embed_model = get_model()\n","snap = Snapshot(fold=config.FOLD_TO_RUN,snapshot_epochs=[5,8])\n","model.summary()\n","\n","if config.RESUME:   \n","    model.load_weights(config.resume_model_wts)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:24:45.676623Z","iopub.status.busy":"2022-02-02T10:24:45.676277Z","iopub.status.idle":"2022-02-02T10:32:49.674536Z","shell.execute_reply":"2022-02-02T10:32:49.673361Z","shell.execute_reply.started":"2022-02-02T10:24:45.676581Z"},"trusted":true},"outputs":[],"source":["print('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n","      (config.IMAGE_SIZE,config.EFF_NET,config.BATCH_SIZE))\n","\n","history = model.fit(train_dataset,\n","                validation_data = val_dataset,\n","                steps_per_epoch = STEPS_PER_EPOCH,\n","                epochs = config.EPOCHS,\n","                callbacks = [snap,get_lr_callback(),train_logger,sv_loss], \n","                verbose = VERBOSE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-02T10:32:53.824537Z","iopub.status.busy":"2022-02-02T10:32:53.824249Z","iopub.status.idle":"2022-02-02T10:33:00.408649Z","shell.execute_reply":"2022-02-02T10:33:00.407304Z","shell.execute_reply.started":"2022-02-02T10:32:53.824508Z"},"trusted":true},"outputs":[],"source":["model.load_weights(config.save_dir+f\"/{config.MODEL_NAME}_loss.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.708354Z","iopub.status.idle":"2022-02-02T10:23:42.709134Z","shell.execute_reply":"2022-02-02T10:23:42.708869Z","shell.execute_reply.started":"2022-02-02T10:23:42.708837Z"},"trusted":true},"outputs":[],"source":["def get_ids(filename):\n","    ds = get_test_dataset([filename],get_names=True).map(lambda image, image_name: image_name).unbatch()\n","    NUM_IMAGES = count_data_items([filename])\n","    ids = next(iter(ds.batch(NUM_IMAGES))).numpy().astype('U')\n","    return ids\n","\n","def get_targets(filename):\n","    ds = get_eval_dataset([filename],get_targets=True).map(lambda image, target: target).unbatch()\n","    NUM_IMAGES = count_data_items([filename])\n","    ids = next(iter(ds.batch(NUM_IMAGES))).numpy()\n","    return ids\n","\n","def get_embeddings(filename):\n","    ds = get_test_dataset([filename],get_names=False)\n","    embeddings = embed_model.predict(ds,verbose=0)\n","    return embeddings\n","\n","def get_predictions(test_df,threshold=0.2):\n","    predictions = {}\n","    for i,row in tqdm(test_df.iterrows()):\n","        if row.image in predictions:\n","            if len(predictions[row.image])==5:\n","                continue\n","            predictions[row.image].append(row.target)\n","        elif row.confidence>threshold:\n","            predictions[row.image] = [row.target,'new_individual']\n","        else:\n","            predictions[row.image] = ['new_individual',row.target]\n","\n","    for x in tqdm(predictions):\n","        if len(predictions[x])<5:\n","            remaining = [y for y in sample_list if y not in predictions]\n","            predictions[x] = predictions[x]+remaining\n","            predictions[x] = predictions[x][:5]\n","        \n","    return predictions\n","\n","def map_per_image(label, predictions):\n","    \"\"\"Computes the precision score of one image.\n","\n","    Parameters\n","    ----------\n","    label : string\n","            The true label of the image\n","    predictions : list\n","            A list of predicted elements (order does matter, 5 predictions allowed per image)\n","\n","    Returns\n","    -------\n","    score : double\n","    \"\"\"    \n","    try:\n","        return 1 / (predictions[:5].index(label) + 1)\n","    except ValueError:\n","        return 0.0\n","    \n","f = open ('../input/individual_ids.json', \"r\")\n","target_encodings = json.loads(f.read())\n","target_encodings = {target_encodings[x]:x for x in target_encodings}\n","sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.710821Z","iopub.status.idle":"2022-02-02T10:23:42.711559Z","shell.execute_reply":"2022-02-02T10:23:42.711172Z","shell.execute_reply.started":"2022-02-02T10:23:42.711145Z"},"trusted":true},"outputs":[],"source":["train_targets = []\n","train_embeddings = []\n","for filename in tqdm(TRAINING_FILENAMES):\n","    embeddings = get_embeddings(filename)\n","    targets = get_targets(filename)\n","    train_embeddings.append(embeddings)\n","    train_targets.append(targets)\n","train_embeddings = np.concatenate(train_embeddings)\n","train_targets = np.concatenate(train_targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.712971Z","iopub.status.idle":"2022-02-02T10:23:42.713464Z","shell.execute_reply":"2022-02-02T10:23:42.713229Z","shell.execute_reply.started":"2022-02-02T10:23:42.713205Z"},"trusted":true},"outputs":[],"source":["from sklearn.neighbors import NearestNeighbors\n","neigh = NearestNeighbors(n_neighbors=config.KNN,metric='cosine')\n","neigh.fit(train_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.714555Z","iopub.status.idle":"2022-02-02T10:23:42.715047Z","shell.execute_reply":"2022-02-02T10:23:42.714814Z","shell.execute_reply.started":"2022-02-02T10:23:42.714789Z"},"trusted":true},"outputs":[],"source":["test_ids = []\n","test_nn_distances = []\n","test_nn_idxs = []\n","val_targets = []\n","val_embeddings = []\n","for filename in tqdm(VALIDATION_FILENAMES):\n","    embeddings = get_embeddings(filename)\n","    targets = get_targets(filename)\n","    ids = get_ids(filename)\n","    distances,idxs = neigh.kneighbors(embeddings, config.KNN, return_distance=True)\n","    test_ids.append(ids)\n","    test_nn_idxs.append(idxs)\n","    test_nn_distances.append(distances)\n","    val_embeddings.append(embeddings)\n","    val_targets.append(targets)\n","test_nn_distances = np.concatenate(test_nn_distances)\n","test_nn_idxs = np.concatenate(test_nn_idxs)\n","test_ids = np.concatenate(test_ids)\n","val_embeddings = np.concatenate(val_embeddings)\n","val_targets = np.concatenate(val_targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.717308Z","iopub.status.idle":"2022-02-02T10:23:42.717784Z","shell.execute_reply":"2022-02-02T10:23:42.717547Z","shell.execute_reply.started":"2022-02-02T10:23:42.717524Z"},"trusted":true},"outputs":[],"source":["allowed_targets = set([target_encodings[x] for x in np.unique(train_targets)])\n","val_targets_df = pd.DataFrame(np.stack([test_ids,val_targets],axis=1),columns=['image','target'])\n","val_targets_df['target'] = val_targets_df['target'].astype(int).map(target_encodings)\n","val_targets_df.loc[~val_targets_df.target.isin(allowed_targets),'target'] = 'new_individual'\n","val_targets_df.target.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.719215Z","iopub.status.idle":"2022-02-02T10:23:42.719672Z","shell.execute_reply":"2022-02-02T10:23:42.719457Z","shell.execute_reply.started":"2022-02-02T10:23:42.719433Z"},"trusted":true},"outputs":[],"source":["test_df = []\n","for i in tqdm(range(len(test_ids))):\n","    id_ = test_ids[i]\n","    targets = train_targets[test_nn_idxs[i]]\n","    distances = test_nn_distances[i]\n","    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n","    subset_preds['image'] = id_\n","    test_df.append(subset_preds)\n","test_df = pd.concat(test_df).reset_index(drop=True)\n","test_df['confidence'] = 1-test_df['distances']\n","test_df = test_df.groupby(['image','target']).confidence.max().reset_index()\n","test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\n","test_df['target'] = test_df['target'].map(target_encodings)\n","test_df.to_csv('val_neighbors.csv')\n","test_df.image.value_counts().value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.720784Z","iopub.status.idle":"2022-02-02T10:23:42.721279Z","shell.execute_reply":"2022-02-02T10:23:42.721018Z","shell.execute_reply.started":"2022-02-02T10:23:42.720994Z"},"trusted":true},"outputs":[],"source":["## Compute CV\n","best_th = 0\n","best_cv = 0\n","for th in [0.1*x for x in range(11)]:\n","    all_preds = get_predictions(test_df,threshold=th)\n","    cv = 0\n","    for i,row in val_targets_df.iterrows():\n","        target = row.target\n","        preds = all_preds[row.image]\n","        val_targets_df.loc[i,th] = map_per_image(target,preds)\n","    cv = val_targets_df[th].mean()\n","    print(f\"CV at threshold {th}: {cv}\")\n","    if cv>best_cv:\n","        best_th = th\n","        best_cv = cv"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.722999Z","iopub.status.idle":"2022-02-02T10:23:42.723333Z","shell.execute_reply":"2022-02-02T10:23:42.723181Z","shell.execute_reply.started":"2022-02-02T10:23:42.723161Z"},"trusted":true},"outputs":[],"source":["print(\"Best threshold\",best_th)\n","print(\"Best cv\",best_cv)\n","val_targets_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.724617Z","iopub.status.idle":"2022-02-02T10:23:42.724982Z","shell.execute_reply":"2022-02-02T10:23:42.724824Z","shell.execute_reply.started":"2022-02-02T10:23:42.724803Z"},"trusted":true},"outputs":[],"source":["## Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\n","val_targets_df['is_new_individual'] = val_targets_df.target=='new_individual'\n","print(val_targets_df.is_new_individual.value_counts().to_dict())\n","val_scores = val_targets_df.groupby('is_new_individual').mean().T\n","val_scores['adjusted_cv'] = val_scores[True]*0.1+val_scores[False]*0.9\n","best_threshold_adjusted = val_scores['adjusted_cv'].idxmax()\n","print(\"best_threshold\",best_threshold_adjusted)\n","val_scores"]},{"cell_type":"markdown","metadata":{},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.72634Z","iopub.status.idle":"2022-02-02T10:23:42.726658Z","shell.execute_reply":"2022-02-02T10:23:42.726509Z","shell.execute_reply.started":"2022-02-02T10:23:42.726489Z"},"trusted":true},"outputs":[],"source":["train_embeddings = np.concatenate([train_embeddings,val_embeddings])\n","train_targets = np.concatenate([train_targets,val_targets])\n","print(train_embeddings.shape,train_targets.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.728463Z","iopub.status.idle":"2022-02-02T10:23:42.729057Z","shell.execute_reply":"2022-02-02T10:23:42.728856Z","shell.execute_reply.started":"2022-02-02T10:23:42.728813Z"},"trusted":true},"outputs":[],"source":["from sklearn.neighbors import NearestNeighbors\n","neigh = NearestNeighbors(n_neighbors=config.KNN,metric='cosine')\n","neigh.fit(train_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.729972Z","iopub.status.idle":"2022-02-02T10:23:42.730293Z","shell.execute_reply":"2022-02-02T10:23:42.730145Z","shell.execute_reply.started":"2022-02-02T10:23:42.730125Z"},"trusted":true},"outputs":[],"source":["test_ids = []\n","test_nn_distances = []\n","test_nn_idxs = []\n","for filename in tqdm(test_files):\n","    embeddings = get_embeddings(filename)\n","    ids = get_ids(filename)\n","    distances,idxs = neigh.kneighbors(embeddings, config.KNN, return_distance=True)\n","    test_ids.append(ids)\n","    test_nn_idxs.append(idxs)\n","    test_nn_distances.append(distances)\n","test_nn_distances = np.concatenate(test_nn_distances)\n","test_nn_idxs = np.concatenate(test_nn_idxs)\n","test_ids = np.concatenate(test_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.731626Z","iopub.status.idle":"2022-02-02T10:23:42.732092Z","shell.execute_reply":"2022-02-02T10:23:42.731873Z","shell.execute_reply.started":"2022-02-02T10:23:42.73185Z"},"trusted":true},"outputs":[],"source":["sample_submission = pd.read_csv('../input/sample_submission.csv',index_col='image')\n","print(len(test_ids),len(sample_submission))\n","test_df = []\n","for i in tqdm(range(len(test_ids))):\n","    id_ = test_ids[i]\n","    targets = train_targets[test_nn_idxs[i]]\n","    distances = test_nn_distances[i]\n","    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n","    subset_preds['image'] = id_\n","    test_df.append(subset_preds)\n","test_df = pd.concat(test_df).reset_index(drop=True)\n","test_df['confidence'] = 1-test_df['distances']\n","test_df = test_df.groupby(['image','target']).confidence.max().reset_index()\n","test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\n","test_df['target'] = test_df['target'].map(target_encodings)\n","test_df.to_csv('test_neighbors.csv')\n","test_df.image.value_counts().value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.733445Z","iopub.status.idle":"2022-02-02T10:23:42.733828Z","shell.execute_reply":"2022-02-02T10:23:42.733618Z","shell.execute_reply.started":"2022-02-02T10:23:42.733596Z"},"trusted":true},"outputs":[],"source":["sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:23:42.734969Z","iopub.status.idle":"2022-02-02T10:23:42.735297Z","shell.execute_reply":"2022-02-02T10:23:42.735145Z","shell.execute_reply.started":"2022-02-02T10:23:42.735123Z"},"trusted":true},"outputs":[],"source":["predictions = {}\n","for i,row in tqdm(test_df.iterrows()):\n","    if row.image in predictions:\n","        if len(predictions[row.image])==5:\n","            continue\n","        predictions[row.image].append(row.target)\n","    elif row.confidence>best_threshold_adjusted:\n","        predictions[row.image] = [row.target,'new_individual']\n","    else:\n","        predictions[row.image] = ['new_individual',row.target]\n","        \n","for x in tqdm(predictions):\n","    if len(predictions[x])<5:\n","        remaining = [y for y in sample_list if y not in predictions]\n","        predictions[x] = predictions[x]+remaining\n","        predictions[x] = predictions[x][:5]\n","    predictions[x] = ' '.join(predictions[x])\n","    \n","predictions = pd.Series(predictions).reset_index()\n","predictions.columns = ['image','predictions']\n","predictions.to_csv('submission.csv',index=False)\n","predictions.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
